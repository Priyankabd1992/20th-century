# Import libraries

import pandas as pd
import time
from selenium.webdriver.chrome.options import Options
import matplotlib.pyplot as plt 
import os
import logging
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities


# Path to ChromeDriver (use raw string or double backslashes)
chrome_driver_path = r'C:\Program Files\chromedriver_win32.exe'  # Adjust as needed

# Use webdriver_manager to automatically download the correct version of ChromeDriver
chrome_driver_path = ChromeDriverManager().install()

# Set up the Chrome driver with the Service object
service = Service(chrome_driver_path)
driver = webdriver.Chrome(service=service)

# URL of the "Key Events of the 20th Century" page 
url = 'https://en.wikipedia.org/wiki/Key_events_of_the_20th_century'


# Open the URL with Selenium
driver.get(url)

# Fetch the page source once it's fully loaded
page_source = driver.page_source


# Use BeautifulSoup to parse the HTML content
from bs4 import BeautifulSoup
soup = BeautifulSoup(page_source, 'html.parser')


# Example: Find and extract the events from a specific section (update the tag/class to match the page structure)
events_section = soup.find_all('div', class_='wikitable')  # Example tag/clas


# Loop through the events and print them
for event in events_section:
    print(event.get_text(strip=True))

# Close the driver after scraping
driver.quit()